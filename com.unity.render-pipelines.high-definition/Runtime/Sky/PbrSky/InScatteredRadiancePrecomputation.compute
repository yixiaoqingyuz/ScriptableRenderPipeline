#pragma enable_d3d11_debug_symbols
#pragma only_renderers d3d11 ps4 xboxone vulkan metal switch
#pragma kernel main

#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Sky/PbrSky/PbrSkyCommon.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Sampling/Sampling.hlsl"

#define TABLE_SIZE uint3(PBRSKYCONFIG_IN_SCATTERED_RADIANCE_TABLE_SIZE_X, \
                         PBRSKYCONFIG_IN_SCATTERED_RADIANCE_TABLE_SIZE_Y, \
                         PBRSKYCONFIG_IN_SCATTERED_RADIANCE_TABLE_SIZE_Z)

RW_TEXTURE3D(float4, _InScatteredRadianceTable); // Emulate a 4D texture with a "deep" 3D texture

[numthreads(4, 4, 4)]
void main(uint3 dispatchThreadId : SV_DispatchThreadID)
{
    const uint zTexSize = PBRSKYCONFIG_IN_SCATTERED_RADIANCE_TABLE_SIZE_Z;
    const uint zTexCnt  = PBRSKYCONFIG_IN_SCATTERED_RADIANCE_TABLE_SIZE_W;

    const float3 scale = rcp(TABLE_SIZE);
    const float3 bias  = 0.5 * scale;

    // Let the hardware and the driver handle the ordering of the computation.
    uint3 tableCoord = dispatchThreadId;
    uint  texId      = dispatchThreadId.z / zTexSize;

    // We don't care about the extremal points (boundary values).
    float3 uvw = tableCoord * scale + bias;

    // Convention:
    // V points towards the camera.
    // The normal vector N points upwards (local Z).
    // The view vector V spans the local XZ plane.
    // The light vector is represented as {phiL, cosThataL}.
    float cosChi = UnmapAerialPerspective(uvw.xy).x;
    float height = UnmapAerialPerspective(uvw.xy).y;
    float cosHor = GetCosineOfHorizonZenithAngle(height);
    float NdotL  = UnmapCosineOfZenithAngle(frac(uvw.z));
    float phiL   = PI * saturate(texId * rcp(zTexCnt - 1));
    float NdotV  = -cosChi;

    float3 N = float3(0, 0, 1);
    float3 V = SphericalToCartesian(0, NdotV);
    float3 L = SphericalToCartesian(phiL, NdotL);

    float LdotV = dot(L, V);
    // float LdotV = SphericalDot(NdotL, phiL, NdotV, 0);

    float3 radiance = 0;

    if (NdotL > cosHor)
    {
        // Sun is directly visible from this position.
        float3 transm  = SampleTransmittanceTexture(NdotL, height, false);
        float3 scatter = AtmosphereScatter(LdotV, height);

        radiance += scatter * transm * _SunRadiance;
    }
    else
    {
        // The sun is occluded by the planet.
    }

    // Integrate ground contribution.
    // The ground is a Lambertian reflector. It is basically a textured sphere light.
    // TODO: a lot of values are almost zero! How to early-out?
    {
        // We will importance sample according to the solid angle.
        // Hard to take transmittance, the phase function and the illumination into account...
        float R = _PlanetaryRadius;
        float h = height;
        float r = R + h;

        float3 P           = r * N;
        float  cosAperture = -cosHor; // Cosine of the half-angle

        const int numGroundSamples = 89;

        for (int i = 0; i < numGroundSamples; i++)
        {
            float2 f = Fibonacci2d(i, numGroundSamples);

            // Construct a direction around the up vector.
            float3 dir; float rcpPdf;
            SampleCone(f, cosAperture, dir, rcpPdf);

            // Flip it upside-down to point towards the sphere light (planet).
            float3 gL = -dir;

            // TODO: compute analytically?
            float  t  = IntersectPlanetFromOutside(gL.z, h);
            float3 gP = P + t * gL;
            float3 gN = normalize(gP);

            // Shade the ground.
            const float3 gBrdf = INV_PI * _GroundAlbedo;

            float3 transm  = SampleTransmittanceTexture(gL.z, h, true);
            float3 scatter = AtmosphereScatter(dot(gL, V), h);

            float weight = rcpPdf * rcp(numGroundSamples);
            radiance += weight * scatter * transm * gBrdf * SampleGroundIrradianceTexture(dot(gN, L));
        }
    }

    // TODO: deep compositing.
    float4 tableEntry = float4(radiance, 1);

    _InScatteredRadianceTable[tableCoord] = tableEntry;
}
